# Module 1 — Developer’s Foundation — Deep Reference

This is the _definitive_ Module 1 reference you can search, bookmark, and come back to.
I expanded every part so you’ve got (1) the conceptual map, (2) practical commands/snippets you can run now, (3) the right vocabulary so you know what to google later, and (4) targeted CNC-relevant examples (G-code parsing and simple tool chains).

---

## Why this module matters (short)

A stable, reproducible environment + fluency with the tools underneath your code is what turns accidental scripts into reliable systems. You’ll stop guessing and start _reasoning_ about problems.

---

## Quick table of contents

1. The layered stack — mental model
2. OS deep dive (processes, memory, files, syscalls)
3. Shell & scripting deep dive (pipes, quoting, file descriptors, advanced patterns)
4. Editors & IDEs — how to use them like a power user
5. Git internals and workflows
6. Package managers & environments (Python, Node, C++, system)
7. Compilers, linkers, interpreters — what they do and why it matters
8. Build tools & project structure (CMake, make, pyproject)
9. Debugging & profiling (gdb, pdb, perf, flamegraphs)
10. Containers & Docker (namespaces, cgroups, multi-stage builds)
11. WSL notes (practical)
12. CNC-centric utilities (awk/sed/G-code examples, streaming parsers)
13. Command cheat-sheet & useful search keywords
14. Exercises & suggested reading

---

## 1 — The layered stack (mental model)

```
Hardware (CPU, RAM, Disks)
  ↑
Operating System (kernel, drivers)
  ↑
Runtimes & System Libraries (libc, libstdc++)
  ↑
Shell / Daemons / Services
  ↑
Editors / Build Tools / Containers
  ↑
Your Code (Python / JS / C++ / scripts)
```

Every time you debug something, ask: _Which layer is failing?_ — hardware, OS, runtime, tool, or code.

---

## 2 — Operating Systems (deep)

### Key responsibilities

- **Process management** — creating, scheduling, terminating processes
- **Memory management** — virtual memory, paging, heap/stack separation
- **I/O and filesystems** — open/read/write/close, block devices vs character devices
- **Security** — users/groups, permissions, capabilities
- **Resource control** — cgroups, namespaces (containers), quotas

### Important concepts & commands

- **Process:** `ps aux`, `top`/`htop`
- **Thread:** threads live inside processes (Linux: `ps -T -p <pid>`)
- **System calls:** low-level API (open/read/write/fork/exec) — trace with `strace <cmd>`
- **Signals:** `SIGINT`, `SIGTERM`, `SIGKILL`, use `kill` to send, trap in shell or code
- **Virtual memory:** `free -h`, `/proc/meminfo` — OS maps virtual addresses to physical pages (swap when needed)
- **File descriptors:** 0 stdin, 1 stdout, 2 stderr — list open fds with `lsof -p <pid>`
- **Permissions:** `ls -l`, `chmod`, `chown`, `sudo`
- **System logs:** `journalctl -u <service>` (systemd), `dmesg` for kernel messages
- **Network sockets:** `ss -tulpn`, `netstat -tulpn` (older), `lsof -i`

### Experiments

- Trace a command’s syscalls:

```bash
strace -o /tmp/trace.txt -f python3 -c 'print("hello")'
less /tmp/trace.txt
```

- See file open/close syscalls for a running process:

```bash
lsof -p $(pgrep -n python)
```

---

## 3 — Shell & scripting (deep)

### Shell vs Terminal

- **Terminal** = emulator window (gnome-terminal, iTerm, Windows Terminal).
- **Shell** = program that interprets commands (bash, zsh, fish, PowerShell).

### Shell primitives

- **Pipelines:** `cmd1 | cmd2` (stdout of cmd1 → stdin of cmd2)
- **Redirection:** `>`, `>>`, `<`, `2>`, `&>`
- **Background jobs:** `&` and job control with `jobs`, `fg`, `bg`
- **Subshells:** `( ... )` spawn separate shell, `{ ...; }` groups without subshell
- **Exit codes:** `$?` — 0 success, non-zero failure
- **set options:** `set -euo pipefail` (stop on errors, treat unset vars as errors, fail pipeline on error) — _use aggressively in scripts_
- **Quoting:** single `'` prevents expansion, double `"` allows expansion; backticks `` `cmd` `` or `$(cmd)` command substitution
- **File descriptors & redirection advanced:** `exec 3>out.txt`, then `echo hi >&3` — useful to open persistent handles
- **Trap for cleanup:** `trap 'rm -f /tmp/lock; exit' EXIT`

### Text processing tools

- `grep` — pattern matching
- `sed` — stream editing (`sed -n '1,10p' file`)
- `awk` — field processing and small programs (powerful)
- `cut`, `sort`, `uniq`, `tr`, `xargs`, `jq` (JSON)

### Useful patterns

Count unique G-code commands:

```bash
grep -Eo '^[GMT][0-9]+' job.gcode | sort | uniq -c | sort -nr
```

Extract X/Y/Z coordinates (simple):

```bash
awk '/^[GM]/ {
  for (i=1;i<=NF;i++) {
    if ($i ~ /^[XYZ]/) print $i
  }
}' job.gcode
```

### Robust script template (bash)

```bash
#!/usr/bin/env bash
set -euo pipefail
IFS=$'\n\t'

# usage check
if [[ $# -lt 1 ]]; then
  echo "Usage: $0 file.gcode" >&2
  exit 2
fi

file="$1"
trap 'echo "exiting"; rm -f /tmp/tmpfile' EXIT

# pipeline example
grep -E '^[GM]' "$file" | awk '{...}'
```

---

## 4 — Editors & IDEs (how to use them well)

### VS Code (recommended for multiple languages)

- **Workspace:** keep `.vscode/settings.json`, `launch.json`, and `tasks.json` for reproducible dev settings.
- **Key extensions:** Python, C/C++, ESLint/Prettier, Docker, GitLens, Remote - Containers, Markdown All-In-One.
- **Useful features:**

  - Integrated terminal (Ctrl+`)
  - Debug configurations for Python/Node/C++
  - Tasks automation for build/test commands
  - Remote containers/workspaces to work inside Docker/WSL

Example `launch.json` for Python:

```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python: Current File",
      "type": "python",
      "request": "launch",
      "program": "${file}"
    }
  ]
}
```

### Vim/Neovim & Emacs

- If you want extreme speed/editor-as-environment, learn Vim/Neovim (modal editing) or Emacs. Use them only if you’re ready to invest hours.
- LSP (Language Server Protocol) bridges editors to provide autocompletion, go-to-definition.

---

## 5 — Git internals & workflows (deep)

### Data model (core)

- **Objects:** blob (file contents), tree (directory listing), commit (meta + tree pointer), tag
- **Hashes:** SHA-1 (or SHA-256 in future variants) are the identity of objects
- **Refs:** `refs/heads/*`, `refs/tags/*` point to commits
- **Index (staging area):** in `.git/index` — the snapshot you will commit

### Plumbing vs Porcelain

- **Porcelain** commands: `git commit`, `git push` — user-friendly
- **Plumbing** commands: `git update-index`, `git cat-file` — for deep debugging and scripts

### Common commands & why

```bash
git init
git add .
git commit -m "message"
git branch feature
git checkout feature
git rebase main   # rewrite to replay on top of main
git merge feature
git log --graph --oneline --all
git reflog        # find lost commits
git bisect start  # find commit that introduced bug
```

- Use `git rebase` for linear history (be careful rewriting shared history).
- Use `git merge --no-ff` for merge commits if you want explicit merge points.

### Hooks & automation

- `.git/hooks/pre-commit`, `pre-push`, `commit-msg` — enforce linting/tests locally with pre-commit.
- `pre-commit` framework (python) is widely used.

### Branching models

- **Trunk-based** — short-lived branches, frequent merges to main
- **Gitflow** — long-running `develop`, `release`, `hotfix` branches (heavier)
- **Feature branch** — common for teams

### Remotes & PRs

- `git remote add origin <url>`, `git push -u origin <branch>`
- On GitHub/GitLab, create PR/MR, use code review, and CI runs tests.

---

## 6 — Package managers & environments

### Python

- **venv / virtualenv** — isolate per-project dependencies:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -r requirements.txt
```

- **pyproject.toml** (PEP 518) modern format; use **poetry** or **pip-tools** for dependency management and lockfiles.
- **pipx** to install single global CLI tools safely.

### Node

- **nvm** to manage Node versions:

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/master/install.sh | bash
nvm install --lts
```

- `npm init`, `npm install`, `npm ci` (use `npm ci` in CI to use lockfile)
- Locks: `package-lock.json` or `yarn.lock`/`pnpm-lock.yaml`.

### C++

- **vcpkg** or **conan** for library management; otherwise vendor libraries or system packages.
- Link-time and ABI considerations: static vs shared libraries.

### System package managers

- `apt` (Ubuntu/Debian), `yum`/`dnf` (RHEL), `brew` (macOS), `winget`/`choco` (Windows)

---

## 7 — Compilers, linkers, interpreters

### C/C++ compile pipeline

1. **Preprocessing**: `#include`, `#define` → output translation unit
2. **Compilation**: source → assembly (`.s`)
3. **Assembly**: assembly → object file (`.o`)
4. **Linking**: link objects + libs → executable

Commands:

```bash
g++ -c file.cpp -o file.o          # compile (no link)
g++ file.o other.o -o program -O2  # link
g++ -g -O0 file.cpp -o program     # include debug info
```

### Linker errors

- `undefined reference` → missing symbol in linking
- Use `nm file.o` and `objdump -t` to inspect symbols

### Interpreters & runtimes

- **CPython**: Python source → bytecode (`.pyc`) → interpreter executes on VM; GIL serializes bytecode execution threads at C level.
- **V8 (Node)**: parses JS, JITs hot functions to machine code.
- **JIT vs AOT**: JIT compiles at runtime (fast for long-running apps); AOT/compiled languages have different tradeoffs.

---

## 8 — Build tools & project structure

### CMake basics

`CMakeLists.txt` minimal:

```cmake
cmake_minimum_required(VERSION 3.20)
project(parser LANGUAGES CXX)
set(CMAKE_CXX_STANDARD 17)
add_executable(parser src/main.cpp src/lexer.cpp)
target_include_directories(parser PRIVATE include)
```

Build:

```bash
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
cmake --build .
```

### Python packaging

- `pyproject.toml` with `poetry` or `flit` or `setuptools`.
- Keep tests under `tests/` and use `pytest`.

### Project layout (example)

```
project/
├── src/
│   └── project_pkg/
├── tests/
├── docs/
├── examples/
├── pyproject.toml / package.json / CMakeLists.txt
```

---

## 9 — Debugging & profiling (practical)

### Debugging compiled code (C/C++)

- Compile with `-g`:

```bash
g++ -g -O0 main.cpp -o main
gdb ./main
# inside gdb:
break main
run
bt        # backtrace
print var
```

- Use `valgrind --leak-check=full ./main` to find leaks (Linux).

### Debugging Python

- `python -m pdb script.py` or use `breakpoint()` (Python 3.7+).
- `pdb` commands: `n` next, `s` step, `c` continue, `l` list, `p` print.

### Profiling

- Python: `cProfile` or `py-spy` (sampling profiler, safe for production). Generate flamegraphs with `py-spy` + speedscope.
- Native: `perf` (Linux), `perf record`, `perf report`. Use `FlameGraph` tools to visualize.

### Logging

- Prefer structured logging (`json`) for services; use different levels (DEBUG/INFO/WARN/ERROR).
- Avoid `print` for production debugging — use logging with timestamps, module names, and levels.

---

## 10 — Docker & containers (conceptual + practical)

### What is a container?

A lightweight, isolated process environment using Linux **namespaces** (isolation) and **cgroups** (resource control). Not a VM — shares the host kernel.

### Minimal Dockerfile (multi-stage)

```dockerfile
# builder
FROM --platform=linux/amd64 python:3.11-slim AS builder
WORKDIR /app
COPY pyproject.toml poetry.lock /app/
RUN pip install poetry && poetry export -f requirements.txt --output requirements.txt
RUN pip wheel --no-deps --wheel-dir /wheels -r requirements.txt

# runtime
FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /wheels /wheels
COPY . /app
RUN pip install --no-index --find-links /wheels -r requirements.txt
CMD ["python", "src/main.py"]
```

### Useful commands

```bash
docker build -t cs-env .
docker run -it --rm -v $(pwd):/app -p 8000:8000 cs-env
docker-compose up --build   # for multi-service stacks
```

### Best practices

- Use small base images (slim, alpine) unless debugging issues.
- Multi-stage builds to avoid shipping build tools in runtime image.
- Pin versions and use lockfiles.
- Mount volumes during development for hot reload; avoid that in production.

---

## 11 — WSL practical notes (Windows users)

- **WSL2** runs a lightweight VM (full Linux kernel) — better compatibility with Docker Desktop (WSL2 backend).
- File system: keep code in the Linux filesystem (`/home/...`) rather than `C:\` for speed.
- Use VS Code Remote - WSL extension to develop seamlessly.
- `wsl --list --verbose`, `wsl -d ubuntu` to start.

---

## 12 — CNC-focused: text processing + streaming G-code parsers

### Small awk example: extract feed rates (F) and spindle speeds (S)

```bash
awk '/^[GM]/ {
  for (i=1;i<=NF;i++) {
    if ($i ~ /^F[0-9]/) print $i;
    if ($i ~ /^S[0-9]/) print $i;
  }
}' job.gcode
```

### Streamed Python parser (generator + context manager)

```python
# gcode_stream.py
import re
from contextlib import contextmanager

token_re = re.compile(r'([GMTXYZFIJE])([-+]?[0-9]*\.?[0-9]+)')

@contextmanager
def open_gcode(path):
    f = open(path, 'r')
    try:
        yield f
    finally:
        f.close()

def stream_tokens(fileobj):
    for lineno, line in enumerate(fileobj, 1):
        line = line.split(';',1)[0].strip()  # strip comments starting with ;
        if not line:
            continue
        # yield command and args
        parts = line.split()
        cmd = parts[0]
        args = {}
        for m in token_re.finditer(line):
            args[m.group(1)] = float(m.group(2))
        yield lineno, cmd, args

if __name__ == "__main__":
    import sys
    path = sys.argv[1]
    with open_gcode(path) as fh:
        for ln, cmd, args in stream_tokens(fh):
            print(ln, cmd, args)
```

- This streams line-by-line (low memory), robust enough to handle large job files.

---

## 13 — Command cheat-sheet (handy to copy)

System & processes:

- `ps aux | grep <prog>`
- `top` / `htop`
- `free -h`, `df -h`
- `dmesg | tail`
- `strace -f -o /tmp/s.txt <cmd>`

Files & text:

- `grep -R "pattern" .`
- `awk '...' file`, `sed -n '1,200p' file`
- `head -n 100 file`, `tail -n 100 file`
- `jq '.key' file.json`

Git:

- `git status`, `git add -A`, `git commit -m "msg"`, `git push`
- `git branch`, `git checkout -b feature`, `git rebase main`
- `git log --graph --decorate --oneline --all`

Docker:

- `docker build -t name .`
- `docker run -it -p 8000:8000 -v $(pwd):/app name`
- `docker ps`, `docker logs <id>`

Debug & profiling:

- `g++ -g -O0 file.cpp -o prog`
- `gdb ./prog`
- `python -m pdb script.py`
- `python -m cProfile -o profile.out script.py`
- `py-spy top -- python script.py` (sampling profiler)

---

## 14 — Search keywords & glossary (what to google next)

Use these exact phrases when you need deep dives:

- `process vs thread Linux`
- `virtual memory paging explanation`
- `system call strace tutorial`
- `file descriptor unix standard streams`
- `bash set -euo pipefail explanation`
- `awk field separator examples`
- `git object model blob tree commit`
- `git reflog restore lost commit`
- `git rebase vs merge`
- `pyproject.toml poetry example`
- `python virtualenv vs venv`
- `nvm install node`
- `gcc compilation phases preprocessing compilation assembly linking`
- `CMakeLists.txt example add_executable target_link_libraries`
- `gdb breakpoint conditional`
- `valgrind memory leak detection`
- `py-spy flamegraph`
- `docker namespaces cgroups explanation`
- `WSL2 vs WSL1 differences`

---

## 15 — Exercises (practical, small, test mastery)

### Exercise A — Reproducible dev container

- Create a `module-01/` folder with `Dockerfile` (multi-stage) and `README.md`.
- Build and run a container that has Python and Node; inside container run `python -c "import sys; print(sys.version)"` and `node -v`.
- Commit to a git repo and push to GitHub.

### Exercise B — Shell + text processing

- Given `job.gcode`, write a pipeline that counts how many times each G-code command (G0, G1, G2, M3, etc.) appears and outputs a sorted count (desc).

### Exercise C — Streaming parser

- Implement the `gcode_stream.py` above, add unit tests (pytest) for parsing lines:

  - `G1 X12.34 Y-5.0 ; move`
  - `M3 S1000`

### Exercise D — Git internals

- Create commits A → B → C. Use `git reflog` to delete B and then recover it. Practice `git bisect` to find a broken commit.

### Exercise E — Debugging

- Write a small C++ program that segfaults; compile with `-g` and use `gdb` to find where it crashes and inspect variables.

---

## 16 — Further reading (canonical references)

- **Pro Git** — [https://git-scm.com/book/en/v2](https://git-scm.com/book/en/v2)
- **Operating Systems: Three Easy Pieces** — [https://pages.cs.wisc.edu/~remzi/OSTEP/](https://pages.cs.wisc.edu/~remzi/OSTEP/)
- **The Linux Programming Interface** (book) — Michael Kerrisk
- **Docker docs** — [https://docs.docker.com/get-started/](https://docs.docker.com/get-started/)
- **Python docs** — [https://docs.python.org/3/](https://docs.python.org/3/)
- **C++ reference** — [https://en.cppreference.com/](https://en.cppreference.com/)
- **CMake docs** — [https://cmake.org/cmake/help/latest/](https://cmake.org/cmake/help/latest/)
- **Crafting Interpreters** — [https://craftinginterpreters.com/](https://craftinginterpreters.com/) (good for language/runtime internals)
- **FlameGraphs** — [https://www.brendangregg.com/flamegraphs.html](https://www.brendangregg.com/flamegraphs.html)

---

## Final notes & how I’ll proceed

- This reference is intentionally practical and searchable. When you’re stuck later, search the **exact keywords** from the glossary — they’ll produce the right deep-dive articles.
- Next steps I can deliver immediately (pick any):

  - Convert this reference into a mkdocs-ready page (I’ll show `mkdocs` frontmatter + markdown ready to paste).
  - Move to **Module 2 (Computer Architecture)** — CPU internals, instruction sets, cache hierarchies, and how that affects code choices (fixed/floating point, alignment, vectorization).
  - Expand any subsection above even deeper (e.g., full git plumbing tutorial, CMake advanced patterns, or a full debugging walkthrough with real examples).

Which one do you want now? If you want the mkdocs-ready markdown, I’ll output that next (complete with frontmatter and anchor links).
